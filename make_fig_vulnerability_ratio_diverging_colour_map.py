#!/usr/bin/env python3
"""
Make Figure â€“ Choropleth of Vulnerability Ratio with Diverging Colour Map.

The vulnerability ratio is defined as:
(% poorest 20% exposed) / (% total population exposed)
= (poorest_20_affected / poorest_20_population) / (total_affected / total_population)

A ratio > 1 indicates the poorest 20% are disproportionately exposed.
A ratio < 1 indicates the poorest 20% are less exposed than the general population.
A ratio = 1 indicates proportional exposure.

The map uses a diverging color scheme centered around a ratio of 1.
The title is placed at the bottom of the figure.
All text is rendered using a sans-serif font.
A detailed text description of the figure is generated.

Usage (example):
    python make_fig_vulnerability_ratio_diverging_colour_map.py --ssp SSP2 --year 2020 --rp RP100
"""
import argparse
import os
import geopandas as gpd
import matplotlib
matplotlib.use("Agg")          # headless / SLURM safe
import matplotlib.pyplot as plt
import mapclassify
import numpy as np
import pandas as pd # For more complex data handling if needed

# Set sans-serif font globally for the script
plt.rcParams['font.family'] = 'sans-serif'

# ----------------------------------------------------------------------
# Hard-wired roots (consistent with other make_fig scripts)
BASE_OUT_DIR = "/hdrive/all_users/wiederkehr/analysis/analysis_runs_output_all_combinations"
FIG_DIR      = "/hdrive/all_users/wiederkehr/analysis/bachelor/"
os.makedirs(FIG_DIR, exist_ok=True)

def build_paths(ssp: str, year: str, rp: str):
    """Constructs file paths for input GeoJSON and output files."""
    results_dir = os.path.join(BASE_OUT_DIR, f"results_{ssp}_{year}_{rp}")
    geojson_path = os.path.join(results_dir, f"analysis_results_{ssp}_{year}_{rp}.geojson")
    
    base_filename = f"vulnerability_ratio_diverging_{ssp}_{year}_{rp}"
    png_path = os.path.join(FIG_DIR, f"{base_filename}.png")
    txt_path = os.path.join(FIG_DIR, f"description_{base_filename}.txt")
    
    return geojson_path, png_path, txt_path

def plot_vulnerability_ratio_diverging(geojson_path: str, png_path: str, txt_path: str, ssp: str, year: str, rp: str):
    """
    Generates a choropleth map of the vulnerability ratio with a diverging color map
    and a detailed text description.
    """
    try:
        gdf = gpd.read_file(geojson_path)
    except Exception as e:
        print(f"Error reading GeoJSON file {geojson_path}: {e}")
        return

    required_cols = ['poorest_20_affected', 'poorest_20_population', 'total_affected', 'total_population']
    for col in required_cols:
        if col not in gdf.columns:
            print(f"Required column '{col}' not found in GeoJSON. Skipping plot generation.")
            # Create an empty text file indicating the error
            with open(txt_path, 'w') as f:
                f.write(f"Error: Required column '{col}' not found in GeoJSON '{geojson_path}'. Plot generation aborted.")
            return

    # Store initial NaN state for required_cols before any modifications to gdf
    initial_input_is_nan = gdf[required_cols].isnull()

    # Calculate shares, handling potential division by zero by yielding NaN
    gdf["share_poorest20_exposed"] = np.where(
        gdf["poorest_20_population"] > 0,
        gdf["poorest_20_affected"] / gdf["poorest_20_population"],
        np.nan
    )
    gdf["share_total_exposed"] = np.where(
        gdf["total_population"] > 0,
        gdf["total_affected"] / gdf["total_population"],
        np.nan
    )

    # Calculate vulnerability ratio (raw, before inf replacement)
    # This helps distinguish between 0/0 (NaN) and X/0 (inf)
    gdf["vulnerability_ratio_raw"] = gdf["share_poorest20_exposed"] / gdf["share_total_exposed"]

    # Final ratio after inf replacement
    gdf["vulnerability_ratio"] = gdf["vulnerability_ratio_raw"].replace([np.inf, -np.inf], np.nan)

    data_col_name = "vulnerability_ratio"
    valid_data = gdf[data_col_name].dropna()
    all_nan_gdf = gdf[gdf[data_col_name].isnull()].copy() # Use .copy() to avoid SettingWithCopyWarning

    # --- Categorize NaN regions ---
    nan_case_counts = {
        'initial_input_nan': 0,
        'zero_p20_pop': 0,
        'zero_total_pop': 0,
        'ratio_0_div_0': 0,
        'ratio_x_div_0': 0, # Inf converted to NaN
        'unexplained_nan': 0 
    }
    nan_case_examples = {
        'initial_input_nan': [],
        'zero_p20_pop': [],
        'zero_total_pop': [],
        'ratio_0_div_0': [],
        'ratio_x_div_0': [],
        'unexplained_nan': []
    }
    MAX_EXAMPLES_PER_CASE = 3

    # Determine region identifier column
    if 'nuts_id' in gdf.columns:
        region_id_col = 'nuts_id'
    elif 'region_name' in gdf.columns:
        region_id_col = 'region_name'
    else:
        # If no specific ID column, use the index. Convert to string for consistency.
        all_nan_gdf['_temp_id_col_'] = all_nan_gdf.index.astype(str)
        region_id_col = '_temp_id_col_'

    for idx, row in all_nan_gdf.iterrows():
        region_identifier = str(row[region_id_col])
        
        # Case 3: Propagation of Missing Input Data (checks the original required columns for this specific row index)
        if initial_input_is_nan.loc[idx].any():
            nan_case_counts['initial_input_nan'] += 1
            if len(nan_case_examples['initial_input_nan']) < MAX_EXAMPLES_PER_CASE:
                nan_case_examples['initial_input_nan'].append(region_identifier)
            continue # Prioritize this as the root cause

        # Case 1a: Zero poorest_20_population (original population was 0)
        # Check original gdf for this, as row is from all_nan_gdf which might have derived NaNs
        if gdf.loc[idx, 'poorest_20_population'] == 0:
            nan_case_counts['zero_p20_pop'] += 1
            if len(nan_case_examples['zero_p20_pop']) < MAX_EXAMPLES_PER_CASE:
                nan_case_examples['zero_p20_pop'].append(region_identifier)
            continue
            
        # Case 1b: Zero total_population (original population was 0, and p20_pop was not 0)
        if gdf.loc[idx, 'total_population'] == 0:
            nan_case_counts['zero_total_pop'] += 1
            if len(nan_case_examples['zero_total_pop']) < MAX_EXAMPLES_PER_CASE:
                nan_case_examples['zero_total_pop'].append(region_identifier)
            continue

        # Case 2b: X/0 (Inf converted to NaN) - check the raw ratio for Inf
        if np.isinf(row['vulnerability_ratio_raw']):
            nan_case_counts['ratio_x_div_0'] += 1
            if len(nan_case_examples['ratio_x_div_0']) < MAX_EXAMPLES_PER_CASE:
                nan_case_examples['ratio_x_div_0'].append(region_identifier)
            continue

        # Case 2a: 0/0 - both shares were zero, leading to NaN in vulnerability_ratio_raw.
        # Check if raw ratio was NaN AND both shares were 0.
        if pd.isna(row['vulnerability_ratio_raw']) and \
           pd.notna(row['share_poorest20_exposed']) and row['share_poorest20_exposed'] == 0 and \
           pd.notna(row['share_total_exposed']) and row['share_total_exposed'] == 0:
            nan_case_counts['ratio_0_div_0'] += 1
            if len(nan_case_examples['ratio_0_div_0']) < MAX_EXAMPLES_PER_CASE:
                nan_case_examples['ratio_0_div_0'].append(region_identifier)
            continue
            
        # Fallback for any other NaN reasons not explicitly caught.
        nan_case_counts['unexplained_nan'] +=1
        if len(nan_case_examples['unexplained_nan']) < MAX_EXAMPLES_PER_CASE:
            nan_case_examples['unexplained_nan'].append(region_identifier)
    
    if '_temp_id_col_' in all_nan_gdf.columns: # Check if temp col was added to all_nan_gdf
        pass # No need to drop from original gdf if only added to the copy

    # --- Define plotting scheme and colormap ---
    cmap_to_use = "RdBu_r"  # Red-White-Blue diverging: low ratios blue (less vulnerable), high ratios red (more vulnerable)
    plot_scheme_name = "UserDefined" 
    # Define bins to center around 1.0 for the diverging map
    # Classes: <0.8 | 0.8-0.95 | 0.95-1.05 (neutral) | 1.05-1.2 | >1.2
    # These bins are chosen to highlight deviations from proportional exposure (ratio=1)
    user_defined_bins = []
    if not valid_data.empty:
        min_val = valid_data.min()
        max_val = valid_data.max()
        # Ensure bins cover the full range while focusing on the diverging points
        # Bins must be strictly increasing
        raw_bins = sorted(list(set([min_val, 0.8, 0.95, 1.05, 1.2, max_val])))

        # Special case handling: If the minimum value is greater than or equal to 0.8 and the maximum value is less than or equal to 1.2,
        # we have a situation where all data is within the neutral range. In this case, we should not use UserDefined bins
        # as it won't effectively show the divergence. Fallback to Quantiles.
        if min_val >= 0.8 and max_val <= 1.2:
            plot_scheme_name = "Quantiles" # Fallback if data is narrowly ranged around 1
            user_defined_bins = None
            plot_k_val = 5
            classification_kwargs = {'k': plot_k_val}
        else:
            user_defined_bins.append(raw_bins[0])
            for i in range(1, len(raw_bins)):
                if raw_bins[i] > user_defined_bins[-1]: # Ensure strictly increasing
                     user_defined_bins.append(raw_bins[i])
            
            if len(user_defined_bins) < 2: # Not enough unique bins for classification
                plot_scheme_name = "Quantiles" # Fallback if too few bins
                user_defined_bins = None
                plot_k_val = 5
                classification_kwargs = {'k': plot_k_val}
            else:
                classification_kwargs = {'bins': user_defined_bins}
    else: # No valid data
        plot_scheme_name = "EqualInterval" # Placeholder if no data
        user_defined_bins = [0, 1] # Placeholder
        plot_k_val = 1
        classification_kwargs = {'k': plot_k_val}


    # --- Plotting ---
    fig, ax = plt.subplots(1, 1, figsize=(15, 12))
    
    if not valid_data.empty:
        gdf.plot(column=data_col_name, ax=ax, legend=True,
                 scheme=plot_scheme_name, classification_kwds=classification_kwargs,
                 cmap=cmap_to_use,
                 missing_kwds={"color": "lightgrey", "label": "Missing/Invalid Data"},
                 edgecolor='black', linewidth=0.5)
    else: # Handle empty valid_data case for plotting
        gdf.plot(ax=ax, color="lightgrey", edgecolor='black', linewidth=0.5)
        ax.text(0.5, 0.5, "No valid data to display", horizontalalignment='center', verticalalignment='center', transform=ax.transAxes, fontsize=14)


    ax.set_axis_off() # Turn off the axis numbers and ticks

    plot_title = f"Vulnerability Ratio: {ssp} ({year}), {rp}\n(% Poorest 20% Exposed / % Total Population Exposed)"
    fig.suptitle(plot_title, y=0.05, fontsize=14, ha='center', va='bottom') # Title at the bottom

    plt.tight_layout(rect=[0, 0.06, 1, 0.95]) # Adjust layout to make space for suptitle

    try:
        plt.savefig(png_path, dpi=300, bbox_inches='tight')
        print(f"Saved map to {png_path}")
    except Exception as e:
        print(f"Error saving PNG {png_path}: {e}")
    plt.close(fig)

    # --- Generate TXT description ---
    description_lines = []
    description_lines.append("Figure Description: Choropleth Map of Vulnerability Ratio")
    description_lines.append("====================================================================================================")
    description_lines.append("Analysis Parameters:")
    description_lines.append(f"  - Scenario (SSP): {ssp}")
    description_lines.append(f"  - Year: {year}")
    description_lines.append(f"  - Return Period (RP): {rp}")
    description_lines.append(f'Figure Title (located at bottom of plot): "{plot_title.replace(chr(10), " - ")}"') # Use plot_title directly
    description_lines.append(f"Source Data: GeoJSON file '{os.path.basename(geojson_path)}'")
    description_lines.append("====================================================================================================")
    description_lines.append("")
    description_lines.append("1. General Information:")
    description_lines.append("   - This document describes a choropleth map visualizing the 'vulnerability_ratio' for NUTS regions.")
    description_lines.append("   - The vulnerability ratio is defined as:")
    description_lines.append("     (% poorest 20% of population exposed to flooding) / (% total population exposed to flooding)")
    description_lines.append("     = (poorest_20_affected / poorest_20_population) / (total_affected / total_population)")
    description_lines.append("   - Interpretation of the ratio:")
    description_lines.append("     - Ratio > 1: The poorest 20% of the population are disproportionately more exposed to flooding.")
    description_lines.append("     - Ratio < 1: The poorest 20% of the population are disproportionately less exposed.")
    description_lines.append("     - Ratio = 1: The poorest 20% experience exposure proportional to the total population.")
    description_lines.append("   - The \'vulnerability_ratio\' can be undefined (NaN or Not a Number) for a region due to several specific reasons:")
    description_lines.append("     1. Zero Population Denominators in Share Calculation:")
    description_lines.append("        - If \'poorest_20_population\' is zero for a region, the \'share_poorest20_exposed\' (poorest_20_affected / poorest_20_population) cannot be calculated, leading to NaN for this share and subsequently for the ratio.")
    description_lines.append("        - If \'total_population\' is zero for a region, the \'share_total_exposed\' (total_affected / total_population) cannot be calculated, leading to NaN for this share and subsequently for the ratio.")
    description_lines.append("     2. Division by Zero in Final Ratio Calculation:")
    description_lines.append("        - If \'share_total_exposed\' is calculated as zero (e.g., total_affected is 0, or total_population was valid but no one was affected):")
    description_lines.append("          - And \'share_poorest20_exposed\' is also zero, the ratio becomes 0/0, which is undefined (NaN).")
    description_lines.append("          - And \'share_poorest20_exposed\' is a non-zero positive value, the ratio becomes X/0 (e.g., 0.1 / 0), which is infinite. The script explicitly converts these infinite values to NaN to ensure robust plotting and statistical analysis.")
    description_lines.append("     3. Propagation of Missing Input Data:")
    description_lines.append("        - If any of the primary input data columns (\'poorest_20_affected\', \'poorest_20_population\', \'total_affected\', \'total_population\') originally contained missing values (NaN) for a region, these NaNs would typically propagate through the intermediate share calculations and result in a NaN for the final \'vulnerability_ratio\'.")
    
    description_lines.append("   - Quantitative Breakdown of Regions with Undefined (NaN) Vulnerability Ratios:")
    total_nan_regions_from_gdf = gdf[data_col_name].isnull().sum()
    description_lines.append(f"     - Total regions with NaN ratio (from final GDF column): {total_nan_regions_from_gdf}")
    description_lines.append(f"     - Total NaN regions categorized by script: {sum(nan_case_counts.values())} (This should ideally match the count above).")

    # Detailed breakdown:
    desc_initial_nan = f"     - Category 3 (Missing Initial Input): {nan_case_counts['initial_input_nan']} regions. One or more of ('poorest_20_affected', 'poorest_20_population', 'total_affected', 'total_population') were NaN."
    if nan_case_examples['initial_input_nan']:
        desc_initial_nan += f" Examples: {', '.join(map(str, nan_case_examples['initial_input_nan']))}."
    description_lines.append(desc_initial_nan)

    desc_zero_p20 = f"     - Category 1a (Zero Poorest 20% Pop): {nan_case_counts['zero_p20_pop']} regions. 'poorest_20_population' was zero. (Evaluated if initial inputs were not NaN)."
    if nan_case_examples['zero_p20_pop']:
        desc_zero_p20 += f" Examples: {', '.join(map(str, nan_case_examples['zero_p20_pop']))}."
    description_lines.append(desc_zero_p20)

    desc_zero_total = f"     - Category 1b (Zero Total Pop): {nan_case_counts['zero_total_pop']} regions. 'total_population' was zero (and 'poorest_20_population' was not zero). (Evaluated if initial inputs not NaN and p20 pop not zero)."
    if nan_case_examples['zero_total_pop']:
        desc_zero_total += f" Examples: {', '.join(map(str, nan_case_examples['zero_total_pop']))}."
    description_lines.append(desc_zero_total)
    
    desc_x_div_0 = f"     - Category 2b (Ratio X/0 -> Inf -> NaN): {nan_case_counts['ratio_x_div_0']} regions. 'share_total_exposed' was zero while 'share_poorest20_exposed' was non-zero. (Evaluated after previous checks)."
    if nan_case_examples['ratio_x_div_0']:
        desc_x_div_0 += f" Examples: {', '.join(map(str, nan_case_examples['ratio_x_div_0']))}."
    description_lines.append(desc_x_div_0)

    desc_0_div_0 = f"     - Category 2a (Ratio 0/0 -> NaN): {nan_case_counts['ratio_0_div_0']} regions. Both 'share_poorest20_exposed' and 'share_total_exposed' were zero. (Evaluated after previous checks)."
    if nan_case_examples['ratio_0_div_0']:
        desc_0_div_0 += f" Examples: {', '.join(map(str, nan_case_examples['ratio_0_div_0']))}."
    description_lines.append(desc_0_div_0)

    if nan_case_counts['unexplained_nan'] > 0:
        desc_unexplained = f"     - Category (Other/Unexplained NaN): {nan_case_counts['unexplained_nan']} regions. Ratio is NaN for reasons not covered by the specific checks above (should ideally be 0 if logic is complete)."
        if nan_case_examples['unexplained_nan']:
            desc_unexplained += f" Examples: {', '.join(map(str, nan_case_examples['unexplained_nan']))}."
        description_lines.append(desc_unexplained)

    description_lines.append("") # Existing empty line
    description_lines.append("2. Data Column Used for Visualization:")
    description_lines.append(f"   - \'{data_col_name}\' (calculated as described above).")
    description_lines.append("")
    description_lines.append("3. Descriptive Statistics for 'vulnerability_ratio':")
    description_lines.append(f"   - Total number of regions in dataset: {len(gdf)}")
    description_lines.append(f"   - Number of regions with valid '{data_col_name}' data: {valid_data.count()}")
    description_lines.append(f"   - Number of regions with no data (NaN/Inf) for '{data_col_name}': {gdf[data_col_name].isnull().sum()}")
    if not valid_data.empty:
        description_lines.append(f"   - Minimum ratio: {valid_data.min():.2f}")
        description_lines.append(f"   - Maximum ratio: {valid_data.max():.2f}")
        description_lines.append(f"   - Mean ratio: {valid_data.mean():.2f}")
        description_lines.append(f"   - Median ratio: {valid_data.median():.2f}")
        description_lines.append(f"   - Standard Deviation of ratio: {valid_data.std():.2f}")
    else:
        description_lines.append("   - No valid data available for statistical summary.")
    description_lines.append("")
    description_lines.append("4. Classification and Legend:")
    description_lines.append(f"   - Colormap: '{cmap_to_use}' (Diverging: e.g., Red for high ratio, Blue for low ratio, White/Light Grey near 1).")
    description_lines.append(f"   - Classification Scheme: '{plot_scheme_name}'.")
    
    actual_k_classes_for_desc = 0
    classification_bins_str = "N/A"
    if not valid_data.empty:
        try:
            classifier = mapclassify.CLASSIFIERS[plot_scheme_name.lower()](valid_data, **classification_kwargs)
            actual_k_classes_for_desc = classifier.k
            classification_bins_str = ", ".join([f"{b:.2f}" for b in classifier.bins])
            if plot_scheme_name == "UserDefined": # Bins are explicit upper bounds of classes
                 # For UserDefined, bins are the upper limits. The classes are like [min, bin1], (bin1, bin2], ... (bink-1, max]
                 # Or if bins are [b0, b1, b2, b3], classes are (-inf, b0], (b0,b1], (b1,b2], (b2,b3], (b3, inf) if bins are splitters
                 # mapclassify bins for UserDefined are the upper bounds of each class.
                 # So if bins are [0.8, 0.95, 1.05, 1.2, max_val], classes are [min_val, 0.8], (0.8, 0.95] ...
                 class_ranges = []
                 lower_bound = valid_data.min()
                 for upper_bound in classifier.bins:
                     class_ranges.append(f"({lower_bound:.2f} - {upper_bound:.2f}]")
                     lower_bound = upper_bound
                 # If the max value is not the last bin, it implies an open upper class
                 if valid_data.max() > classifier.bins[-1] and len(classifier.bins) > 0 :
                     # This case is tricky with UserDefined if max_val was part of the bins.
                     # Let's just report the bins as they are.
                     pass
                 classification_bins_str = f"Upper bounds: {', '.join([f'{b:.2f}' for b in classifier.bins])}"


        except Exception as e:
            classification_bins_str = f"Error in retrieving bins: {e}"
            actual_k_classes_for_desc = len(user_defined_bins) -1 if user_defined_bins and len(user_defined_bins) > 1 else "N/A (fallback)"


    description_lines.append(f"   - Number of Classes: {actual_k_classes_for_desc}")
    description_lines.append(f"   - Bin Edges/Class Breaks: {classification_bins_str}")
    description_lines.append("   - Legend Description: Shows ranges of the vulnerability ratio, with colors indicating the degree and direction of disproportionate exposure relative to a ratio of 1.")
    description_lines.append("")
    description_lines.append("5. Regional Highlights (based on 'vulnerability_ratio' and defined bins):")
    
    # Use the specific bins for categorization if UserDefined was successful
    # Bins: [min_val, 0.8, 0.95, 1.05, 1.2, max_val] (example)
    # Categories: <0.8, 0.8-0.95, 0.95-1.05, 1.05-1.2, >1.2
    
    cat_labels_values = [
        ("Significantly lower exposure (ratio < 0.8)", (None, 0.8)),
        ("Moderately lower exposure (0.8 <= ratio < 0.95)", (0.8, 0.95)),
        ("Approximately proportional exposure (0.95 <= ratio < 1.05)", (0.95, 1.05)),
        ("Moderately higher exposure (1.05 <= ratio < 1.2)", (1.05, 1.2)),
        ("Significantly higher exposure (ratio >= 1.2)", (1.2, None))
    ]

    region_id_col = 'nuts_id' if 'nuts_id' in gdf.columns else ('region_name' if 'region_name' in gdf.columns else gdf.index.name)
    if region_id_col is None: region_id_col = "index" # fallback

    for label, (low, high) in cat_labels_values:
        if not valid_data.empty:
            if low is None: # < high
                subset = gdf[gdf[data_col_name] < high]
            elif high is None: # >= low
                subset = gdf[gdf[data_col_name] >= low]
            else: # low <= ratio < high
                subset = gdf[(gdf[data_col_name] >= low) & (gdf[data_col_name] < high)]
            
            description_lines.append(f"   - {label}:")
            description_lines.append(f"     - Count: {len(subset)}")
            if not subset.empty and len(subset) <= 5 : # List a few if count is small
                ids = subset[region_id_col].tolist()
                description_lines.append(f"     - Regions: {', '.join(map(str, ids))}")
            elif len(subset) > 5:
                 description_lines.append(f"     - (Regions not listed due to count > 5)")

        else:
            description_lines.append(f"   - {label}: Count: 0 (No valid data)")


    if not valid_data.empty:
        top_n = 5
        top_regions = gdf.nlargest(top_n, data_col_name)
        description_lines.append(f"   - Top {top_n} regions with the highest '{data_col_name}':")
        for idx, row in top_regions.iterrows():
            description_lines.append(f"     - {row[region_id_col]}: {row[data_col_name]:.2f}")
        
        bottom_regions = gdf.nsmallest(top_n, data_col_name) # Includes 0, excludes NaN
        description_lines.append(f"   - Top {top_n} regions with the lowest '{data_col_name}' (excluding NaNs):")
        for idx, row in bottom_regions.iterrows():
            description_lines.append(f"     - {row[region_id_col]}: {row[data_col_name]:.2f}")
    description_lines.append("")
    description_lines.append("6. Plot Layout and Visual Details:")
    description_lines.append("   - Type: Choropleth map.")
    description_lines.append("   - Geographic Scope: NUTS regions (Europe).")
    description_lines.append("   - Borders: Country/NUTS region borders displayed (edgecolor='black', linewidth=0.5).")
    description_lines.append("   - Missing Data: Regions with no valid data are shown in light grey.")
    description_lines.append("   - Title: Positioned at the bottom of the figure, includes scenario details.")
    description_lines.append("   - Font: Sans-serif font used for all text elements.")
    description_lines.append(f"   - Figure Size: Approximately {fig.get_size_inches()[0]:.0f}x{fig.get_size_inches()[1]:.0f} inches.")
    description_lines.append("   - Output files:")
    description_lines.append(f"     - PNG: {os.path.basename(png_path)}")
    description_lines.append(f"     - TXT: {os.path.basename(txt_path)}")
    description_lines.append("")
    description_lines.append("7. Key Data Columns Used (from input GeoJSON):")
    description_lines.append("   - 'geometry': For plotting region shapes.")
    description_lines.append(f"   - '{region_id_col}': For identifying regions in textual descriptions.")
    description_lines.append("   - 'poorest_20_affected': Number of people in poorest 20% income group affected.")
    description_lines.append("   - 'poorest_20_population': Total population in poorest 20% income group.")
    description_lines.append("   - 'total_affected': Total number of people affected.")
    description_lines.append("   - 'total_population': Total population.")
    description_lines.append("====================================================================================================")

    try:
        with open(txt_path, 'w') as f:
            f.write("\n".join(description_lines))
        print(f"Saved text description to {txt_path}")
    except Exception as e:
        print(f"Error saving TXT {txt_path}: {e}")

def main():
    parser = argparse.ArgumentParser(description="Generate a choropleth map of vulnerability ratio with a diverging color map.")
    parser.add_argument("--ssp", type=str, required=True, help="SSP scenario (e.g., SSP2)")
    parser.add_argument("--year", type=str, required=True, help="Year (e.g., 2020)")
    parser.add_argument("--rp", type=str, required=True, help="Return period (e.g., RP100)")
    args = parser.parse_args()

    geojson_path, png_path, txt_path = build_paths(args.ssp, args.year, args.rp)
    
    print(f"Input GeoJSON: {geojson_path}")
    print(f"Output PNG: {png_path}")
    print(f"Output TXT: {txt_path}")

    plot_vulnerability_ratio_diverging(geojson_path, png_path, txt_path, args.ssp, args.year, args.rp)

if __name__ == "__main__":
    main()
